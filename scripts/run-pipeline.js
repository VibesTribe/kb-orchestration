// scripts/run-pipeline.js
// Orchestrates the full incremental knowledge pipeline:
// ingest ‚Üí enrich ‚Üí classify ‚Üí digest ‚Üí publish ‚Üí sync upstream
//
// Additions:
// - Per-stage fail-fast thresholds (plumbed as options; stages may ignore until updated)
// - Clear, mode-specific logging
// - Force daily mode permanently (no fragile bootstrap cache)

import fs from "node:fs/promises";
import path from "node:path";
import { fileURLToPath } from "node:url";

import { ingest } from "./ingest.js";
import { enrich } from "./enrich.js";
import { classify } from "./classify.js";
import { digest } from "./digest.js";
import { publish } from "./publish.js";
import { pullKnowledge, syncKnowledge, syncDigest } from "./lib/kb-sync.js";
import { startUsageRun } from "./lib/token-usage.js";

const __dirname = path.dirname(fileURLToPath(import.meta.url));
const ROOT = path.resolve(__dirname, "..");
const CACHE_DIR = path.join(ROOT, "data", "cache");

// ---- Config (env overrides allowed) ----
const MAX_CONSECUTIVE_FAILS = Number(process.env.MAX_CONSECUTIVE_FAILS ?? 5);

// Helpers
function log(msg, ctx = {}) {
  const ts = new Date().toISOString();
  console.log(`[${ts}] ${msg}`, Object.keys(ctx).length ? ctx : "");
}

async function run() {
  log("üöÄ Starting knowledge pipeline‚Ä¶");

  // NEW: start a fresh token-usage run
  try {
    await startUsageRun();
  } catch (e) {
    log("‚ö†Ô∏è startUsageRun failed; continuing", { error: e?.message });
  }

  // üîí Force daily mode (skip fragile bootstrap-state.json)
  const mode = "daily";

  log("üß≠ Mode selected", {
    mode,
    maxConsecutiveFails: MAX_CONSECUTIVE_FAILS,
  });

  // Options we pass to stages
  const stageOpts = {
    mode,
    failFast: { maxConsecutiveFails: MAX_CONSECUTIVE_FAILS },
  };

  try {
    // 0) Pull canonical knowledge.json first (non-fatal if it fails)
    log("‚¨áÔ∏è Pulling knowledge.json from repo‚Ä¶");
    try {
      await pullKnowledge();
    } catch (e) {
      log("‚ö†Ô∏è pullKnowledge failed; continuing with local knowledge.json", { error: e?.message });
    }

    // 1) Ingest
    log("üì• Ingesting‚Ä¶", { mode });
    await ingest(stageOpts);

    // 2) Enrich
    log("‚ú® Enriching‚Ä¶", { failFastMax: MAX_CONSECUTIVE_FAILS });
    await enrich(stageOpts);

    // 3) Classify
    log("üè∑Ô∏è Classifying‚Ä¶", { failFastMax: MAX_CONSECUTIVE_FAILS });
    await classify(stageOpts);

    // 4) Digest
    log("üì∞ Building digest‚Ä¶");
    const digestResult = await digest(stageOpts);

    // 5) Publish local artifacts
    log("üì§ Publishing‚Ä¶");
    await publish({ digestResult });

    // 6) Sync knowledge.json upstream
    log("‚¨ÜÔ∏è Syncing knowledge.json‚Ä¶");
    await syncKnowledge();

    // 7) Sync digest artifacts, if produced
    if (digestResult) {
      log("‚¨ÜÔ∏è Syncing digest artifacts‚Ä¶");
      await syncDigest(digestResult);
    }

    log("‚úÖ Pipeline completed successfully!");
  } catch (err) {
    log("‚ùå Pipeline failed", { error: err?.message ?? String(err) });
    process.exit(1);
  }
}

run();
